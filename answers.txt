Answers to the text questions go here.

Part 1, (d) When is the Flesch Kincaid score *not* a valid, robust or reliable estimator of 
text difficulty? Give two conditions. (Text answer, 200 words maximum).

Answer:
The Flesch-Kincaid readability test may sometimes provide misleading results depending on the type of text being analysed. 

(1) Informal writing like casual conversations or social media content frequently contains sentence fragments, slang, abbreviations. 
These features can skew traditional measures of sentence and word counts, causing the score to be inaccurate and not necessarily reflect how comprehensible
 the writing is.

(2) Texts with technical jargon, such as scientific or medical articles, often include complex terms and words with many syllables. 
This can artificially raise the reading level score, even if the material is easily understandable by the subject matter experts in the field. 

Overall, when working with content that have specialized vocabulary, irregular formats, or informal language, relying solely on the Flesch-Kincaid score
is not advisable.



Part Two - (f) Explain your tokenizer function and discuss its performance.

Answer:

Tokenizer function:
===================
I have created custom tokenizers using spaCy and NLTK but decided to go ahead with the NLTK implementation for my solution as spaCy-based tokenizer 
has significantly slowed down training and did not yield better performance. `custom_tokenizer_nltk` function is designed for text processing to use with `TfidfVectorizer` vectorization method. 
It breaks the input `text` into individual tokens using NLTK's `word_tokenize` function. Each token is then converted to lowercase to standardize the text. 
The function filters out tokens that are not purely alphabetic or are present in a predefined list of stop words, effectively removing numbers, punctuation,
and common filler words. The remaining tokens are lemmatized using a `lemmatizer`, which reduces words to their base form. This approach ensures that only 
meaningful, standardized, and clean tokens are used for further NLP processing, to improve the quality and efficiency of text analysis. 
I have used this tokenizer with the TfidfVectorizer with max_features in [2000, 2500, 3000], ngram_range=(1, 3) and evaluated with both Random Forest and 
Linear SVM classifiers.

The below results showcase that the SVM consistently outperforms the Random Forest across all tested `max_features` settings, achieving higher 
F1 scores (approximately 0.58 to 0.63) and overall accuracy (around 79% to 81%). Increasing the `max_features` parameter from 2000 to 3000  
improved the performance for both models. Class-wise analysis shows that the "Conservative" and "Scottish National Party" classes are predicted quite 
accurately, with high precision, and F1 scores. However, the "Liberal Democrat" class shows significantly low scores (about 0.07 to 0.25), 
suggesting difficulties in classification that may stem from class imbalance or ineffective feature extraction.


Consolidated table:
===================
SVM report (Outperforms)
==========

max_features       1500     2000     2500      3000

F1 score                    0.58     0.61      0.63  

accuracy                    0.79     0.79      0.81 

Precision                   0.83     0.80      0.82 


Random Forest report
======================
max_features                2000     2500      3000

F1 score                    0.49     0.50      0.52  

accuracy                    0.75     0.74      0.75 

Precision                   0.59     0.85      0.85 

High overall performance:
At max_features=2000, the SVM achieves an accuracy of about 79%, with a good F1 score (~0.58). While not perfect, these are respectable metrics 
indicating solid performance.

Trade-off between performance and efficiency:
Using fewer features (2000 instead of 2500 or 3000) reduces the complexity of the model, saving computational resources while still maintaining relatively
high accuracy and F1 scores. Larger max_features values slightly improve performance but at the cost of increased complexity.


SVM with max_features=2000:
F1 Score: 0.575451745143195
                         precision    recall  f1-score   support

           Conservative       0.82      0.92      0.87       964
                 Labour       0.72      0.68      0.70       463
       Liberal Democrat       1.00      0.06      0.11        54
Scottish National Party       0.77      0.53      0.63       136

               accuracy                           0.79      1617
              macro avg       0.83      0.55      0.58      1617
           weighted avg       0.79      0.79      0.77      1617


SVM with max_features=2500:
F1 Score: 0.6139761098739697
                         precision    recall  f1-score   support

           Conservative       0.82      0.92      0.87       964
                 Labour       0.73      0.68      0.70       463
       Liberal Democrat       0.89      0.15      0.25        54
Scottish National Party       0.77      0.53      0.63       136

               accuracy                           0.79      1617
              macro avg       0.80      0.57      0.61      1617
           weighted avg       0.79      0.79      0.78      1617


SVM with max_features=3000:
F1 Score: 0.6253939424789547
                         precision    recall  f1-score   support

           Conservative       0.83      0.93      0.87       964
                 Labour       0.74      0.70      0.72       463
       Liberal Democrat       0.89      0.15      0.25        54
Scottish National Party       0.80      0.55      0.65       136

               accuracy                           0.80      1617
              macro avg       0.81      0.58      0.63      1617
           weighted avg       0.80      0.80      0.79      1617

